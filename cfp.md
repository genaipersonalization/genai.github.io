# Call for Papers

<h2 style="text-align: center;"> What do we need for successful domain generalization?</h2> 

<p> Website: https://domaingen.github.io/ </p>

The real challenge for any machine learning system is to be reliable and robust in any situation, even if it is different compared to training conditions. Existing general purpose approaches to domain generalization (DG)—a problem setting that challenges a model to generalize well to data outside the distribution sampled at training time—have failed to consistently outperform standard empirical risk minimization baselines. In this workshop, we aim to work towards answering a single question: what do we need for successful domain generalization? We conjecture that additional information of some form is required for a general purpose learning methods to be successful in the DG setting. The purpose of this workshop is to identify possible sources of such information, and demonstrate how these extra sources of data can be leveraged to construct models that are robust to distribution shift. Specific topics of interest include, but are not limited to:
- Leveraging domain-level meta-data
- Exploiting multiple modalities to achieve robustness to distribution shift
- Frameworks for specifying known invariances/domain knowledge
- Causal modeling and how it can be robust to distribution shift
- Empirical analysis of existing domain generalization methods and their underlying assumptions
- Theoretical investigations into the domain generalization problem and potential solutions

### Important dates

- Paper submission deadline: 3 Feb 2023
- Paper acceptance notification: 3 Mar 2023
- Workshop: 5 May 2023


### Submission Instructions:
- Authors should submit papers with up to 5 pages excluding references and supplementary materials via [OpenReview](https://openreview.net/group?id=ICLR.cc/2023/Workshop/DG) .
- Submissions should be formatted using the official ICLR 2023 template which can be found at https://iclr.cc/Conferences/2023/CallForPapers.
- Submissions should be fully anonymized for double-blind review
- Dual submission policy: This workshop welcomes ongoing and unpublished work but will also accept papers that are under review or have recently been accepted at other venues.

### FAQ
- Can previously published paper be submitted to the workshop?: According to ICLR guidelines, workshops are not a venue for work that has been previously published in other conferences on machine learning. Work that is presented at the main ICLR conference should not appear in a workshop, including as part of an invited talk. 
- How to access the workshop on the day of the event: More guidenlines will be added closer to the date of the workshop 

### Invited speakers:
- David Lopez-Paz, Research Scientist at Meta AI Research
- Amos Storkey, Professor in the School of Informatics, University of Edinburgh
- Tatiana Tommasi, Associate Professor at the Department of Control and Computer Engineering of Politecnico di Torino and Affiliated Researcher at the Italian Institute of Technology.
- Lequan Yu, Assistant Professor at The University of Hong Kong.


### Panel:
- Zachary Lipton, Assistant Professor of Machine Learning and Operations Research, Carnegie Mellon University
- Qi Dou, Assistant Professor, Department of Computer Science and Engineering, The Chinese University of Hong Kong
- Boqing Gong, Research Scientist, Google


### Organizers:
- Aniket Deshmukh, Applied Scientist, Microsoft
- Henry Gouk, Machine Learning Researcher, School of Informatics at the University of Edinburgh
- Timothy Hospedales, Professor, School of Informatics at the University of Edinburgh
- Cuiling Lan, Senior Researcher, Microsoft
- Da Li, Senior Research Scientist, Samsung AI
- Kaiyang Zhou, Research Fellow, NTU Singapore
